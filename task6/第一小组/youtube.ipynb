{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from lxml import etree\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "ua = UserAgent(use_cache_server=False)\n",
    "url_root = \"https://www.youtube.com/results?search_query=interview&sp=EgIQAw%253D%253D\"\n",
    "url_head = \"https://www.youtube.com\"\n",
    "header = {\n",
    "        'Accept': 'text/html,*/*',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "        'Connection': 'keep-alive',\n",
    "        'User-Agent': ua.random,\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument('--headless')\n",
    "# chrome_options.add_argument('--disable-gpu')\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "page = [] ##初始化在这个位置！！！！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:0\n",
      "loading:1\n",
      "loading:2\n",
      "loading:3\n",
      "loading:4\n",
      "loading:5\n",
      "loading:6\n",
      "loading:7\n",
      "loading:8\n",
      "loading:9\n",
      "loading:10\n",
      "loading:11\n",
      "loading:12\n",
      "loading:13\n",
      "loading:14\n",
      "loading:15\n",
      "loading:16\n",
      "loading:17\n",
      "loading:18\n",
      "loading:19\n"
     ]
    }
   ],
   "source": [
    "## 主页信息爬取\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Program Files (x86)\\Google\\Chrome\\chromedriver_win32\\chromedriver')\n",
    "driver.get(url_root)\n",
    "for i in range(0,20):\n",
    "    time.sleep(10)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    print(\"loading:%s\" %i)\n",
    "page.append(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存初始列表\n",
    "filename = 'listspage.txt'\n",
    "with open(filename, 'w', encoding = 'utf-8') as f1:\n",
    "    f1.write(page[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_lists = etree.HTML(page[1])\n",
    "viewmore = web_lists.xpath('//yt-formatted-string[@id=\"view-more\"]/a/@href')\n",
    "\n",
    "viewlist = []\n",
    "for line in viewmore:\n",
    "    viewlist.append(url_head+str(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据库初始化\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "detailpage = {\"href\":[]}\n",
    "detailpage = DataFrame(detailpage)\n",
    "youtube = {'uper':[],\n",
    "           'href':[],\n",
    "           'describe':[],\n",
    "           'upload_time':[],\n",
    "           'duration':[],\n",
    "           'viewcount':[],\n",
    "           'upscount':[],\n",
    "           'downscount':[],\n",
    "           'rel_uper':[],\n",
    "           'rel_title':[],\n",
    "           'rel_href':[],\n",
    "           'rel_count':[]}\n",
    "youtube = DataFrame(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据库读入\n",
    "import pandas as pd\n",
    "detailpage = pd.read_csv(\"detailpage.csv\")\n",
    "youtube = pd.read_csv(\"youtube_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "print(len(youtube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:0\n",
      "loading:20\n",
      "loading:40\n",
      "loading:60\n",
      "loading:80\n",
      "loading:100\n"
     ]
    }
   ],
   "source": [
    "## 列表页信息爬取\n",
    "driver = webdriver.Chrome(r'C:\\Program Files (x86)\\Google\\Chrome\\chromedriver_win32\\chromedriver')\n",
    "for i in range(0,len(viewlist)):\n",
    "    status = True\n",
    "    driver.get(viewlist[i])\n",
    "    time.sleep(5)\n",
    "    while status:\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//div[@id=\"content\"]/a')\n",
    "            status = False\n",
    "        except:\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "    \n",
    "    viewvideo = etree.HTML(driver.page_source)\n",
    "    hreflist = viewvideo.xpath('//div[@id=\"content\"]/a/@href')\n",
    "    for line in hreflist:\n",
    "        detailpage = detailpage.append([{\"href\":line}],ignore_index = True)\n",
    "    if (i % 20 == 0):\n",
    "        print(\"loading:%s\" %i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailpage.to_csv(\"detailpage.csv\",index = False, encoding = 'utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##详情页初始化\n",
    "import re\n",
    "clean_re = re.compile('(<.*?>)|(&#.*?;)|( )')\n",
    "buttons_re = re.compile('aria-label=(.*?)>')\n",
    "buttons_clean_re = re.compile('(&#(.*?);)|( )')\n",
    "reluper_re = re.compile(u'(来自|by)(.*?) ')\n",
    "rel_count_re = re.compile(u' ([0-9]{1,3}(,([0-9]){3})*) (次观看|views)')\n",
    "href_re = re.compile(u'href=\"(.*?)\"')\n",
    "title_re = re.compile(u'title=\"(.*?)\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 详情页爬取\n",
    "driver = webdriver.Chrome(r'C:\\Program Files (x86)\\Google\\Chrome\\chromedriver_win32\\chromedriver',options = chrome_options)\n",
    "for i in range(482,len(detailpage['href'])):\n",
    "    addr = url_head+detailpage['href'][i]\n",
    "    detail = [] ###注意这里有一个初始化！！！\n",
    "    driver.get(addr)\n",
    "    status = True\n",
    "    time.sleep(5)\n",
    "    while status:\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//yt-formatted-string[@id=\"owner-name\"]/a')\n",
    "            status = False\n",
    "        except:\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "    \n",
    "    detail = driver.page_source\n",
    "    web = etree.HTML(detail)\n",
    "\n",
    "    uper = web.xpath('//yt-formatted-string[@id=\"owner-name\"]/a/text()')\n",
    "    desc = web.xpath('//div[@id=\"description\"]/yt-formatted-string/text()')\n",
    "    uptime = web.xpath('//div[@id=\"upload-info\"]/span/text()')\n",
    "    duration = web.xpath('//span[@class=\"ytp-time-duration\"]/text()')\n",
    "    viewcount = web.xpath('//div[@id=\"count\"]/yt-view-count-renderer/span[1]/text()')\n",
    "\n",
    "    buttons_raw = web.xpath('//div[@id=\"top-level-buttons\"]/ytd-toggle-button-renderer/a/yt-icon-button/button[@id=\"button\"]')\n",
    "    ups_text_raw = etree.tostring(buttons_raw[0])\n",
    "    downs_text_raw = etree.tostring(buttons_raw[1])\n",
    "    ups_text = buttons_re.findall(str(ups_text_raw))\n",
    "    downs_text = buttons_re.findall(str(downs_text_raw))\n",
    "    ups = buttons_clean_re.sub(\"\",str(ups_text))\n",
    "    downs = buttons_clean_re.sub(\"\",str(downs_text))\n",
    "    \n",
    "    relevant = web.xpath('//div[@class=\"metadata style-scope ytd-compact-video-renderer\"]')\n",
    "    relevant_href = web.xpath('//div[@class=\"metadata style-scope ytd-compact-video-renderer\"]/a/@href')\n",
    "    relevant_info_raw = web.xpath('//div[@class=\"metadata style-scope ytd-compact-video-renderer\"]/a/h3/span')\n",
    "    \n",
    "    relevant_title = []\n",
    "    relevant_uper = []\n",
    "    relevant_count = []\n",
    "    for info in relevant_info_raw:\n",
    "        relevant_info_text = etree.tostring(info, encoding = 'Unicode',pretty_print = True, method = \"html\")\n",
    "        relevant_title.append(title_re.findall(str(relevant_info_text)))\n",
    "        relevant_uper.append(reluper_re.findall(str(relevant_info_text)))\n",
    "        relevant_count.append(rel_count_re.findall(str(relevant_info_text))[0][0])\n",
    "    \n",
    "    youtube = youtube.append([{'uper':uper,\n",
    "                               'href':addr,\n",
    "                               'describe':desc,\n",
    "                               'upload_time':uptime,\n",
    "                               'duration':duration,\n",
    "                               'viewcount':viewcount,\n",
    "                               'upscount':ups,\n",
    "                               'downscount':downs,\n",
    "                               'rel_uper':relevant_uper,\n",
    "                               'rel_title':relevant_title,\n",
    "                               'rel_href':relevant_href,\n",
    "                               'rel_count':relevant_count}],ignore_index = True)\n",
    "    \n",
    "    if (i%20 == 0):\n",
    "        local = time.strftime('%H:%M:%S',time.localtime(time.time()))\n",
    "        print(\"loading:%s：%s\" %(i,local))\n",
    "    if (i%100 == 0):\n",
    "        youtube.to_csv(\"youtube_new.csv\",index = False, encoding = 'utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span id=\"video-title\" class=\"style-scope ytd-compact-video-renderer\" aria-label=\"David Letterman Mathematics Genius Prodigy Daniel Tammet Math 3.14 Pi Day by Jonathan J Crabtree 9 years ago 8 minutes, 14 seconds 8,566,407 views\" title=\"David Letterman Mathematics Genius Prodigy Daniel Tammet Math 3.14 Pi Day\">\n",
      "              David Letterman Mathematics Genius Prodigy Daniel Tammet Math 3.14 Pi Day\n",
      "            </span>\n",
      "          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(relevant_info_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube.to_csv(\"youtube_new.csv\",index = False, encoding = 'utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 详情页信息\n",
    "for line in detail:\n",
    "    web = etree.HTML(line)\n",
    "\n",
    "    uper = web.xpath('//yt-formatted-string[@id=\"owner-name\"]/a/text()')\n",
    "    desc = web.xpath('//div[@id=\"description\"]/yt-formatted-string/text()')\n",
    "    uptime = web.xpath('//div[@id=\"upload-info\"]/span/text()')\n",
    "    duration = web.xpath('//span[@class=\"ytp-time-duration\"]/text()')\n",
    "    viewcount = web.xpath('//div[@id=\"count\"]/yt-view-count-renderer/span[1]/text()')\n",
    "\n",
    "    buttons_raw = web.xpath('//div[@id=\"top-level-buttons\"]/ytd-toggle-button-renderer/a/yt-icon-button/button[@id=\"button\"]')\n",
    "    ups_text_raw = etree.tostring(buttons_raw[0])\n",
    "    downs_text_raw = etree.tostring(buttons_raw[1])\n",
    "    ups_text = buttons_re.findall(str(ups_text_raw))\n",
    "    downs_text = buttons_re.findall(str(downs_text_raw))\n",
    "    ups = buttons_clean_re.sub(\"\",str(ups_text))\n",
    "    downs = buttons_clean_re.sub(\"\",str(downs_text))\n",
    "    \n",
    "    relevant = web.xpath('//div[@class=\"metadata style-scope ytd-compact-video-renderer\"]')\n",
    "    relevant_href = web.xpath('//div[@class=\"metadata style-scope ytd-compact-video-renderer\"]/a/@href')\n",
    "    relevant_info_raw = web.xpath('//div[@class=\"metadata style-scope ytd-compact-video-renderer\"]/a/h3/span')\n",
    "    \n",
    "    relevant_title = []\n",
    "    relevant_uper = []\n",
    "    relevant_count = []\n",
    "    for info in relevant_info_raw:\n",
    "        relevant_info_text = etree.tostring(info, encoding = 'Unicode',pretty_print = True, method = \"html\")\n",
    "        relevant_title.append(title_re.findall(str(relevant_info_text)))\n",
    "        relevant_uper.append(reluper_re.findall(str(relevant_info_text)))\n",
    "        relevant_count.append(rel_count_re.findall(str(relevant_info_text))[0][0])\n",
    "    \n",
    "    youtube = youtube.append([{'uper':uper,\n",
    "           'describe':desc,\n",
    "           'upload_time':uptime,\n",
    "           'duration':duration,\n",
    "           'viewcount':viewcount,\n",
    "           'upscount':ups,\n",
    "           'downscount':downs,\n",
    "           'rel_uper':relevant_uper,\n",
    "           'rel_title':relevant_title,\n",
    "           'rel_href':relevant_href,\n",
    "           'rel_count':relevant_count}],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 主页信息分析 - 8月21日mode\n",
    "import re\n",
    "web = etree.HTML(page[0])\n",
    "block_raw  = web.xpath('//a[@id = \"video-title\"]')\n",
    "\n",
    "block_text = []\n",
    "href = []\n",
    "title = []\n",
    "for line in block_raw:\n",
    "    texts = etree.tostring(line, encoding = 'Unicode')\n",
    "    href.append(href_re.findall(texts))\n",
    "    title.append(title_re.findall(texts))\n",
    "\n",
    "weblist =[]\n",
    "for line in href:\n",
    "    weblist.append(url_head+line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539495\n",
      "435336\n",
      "434203\n",
      "435421\n",
      "430630\n",
      "449654\n",
      "533361\n",
      "439554\n",
      "435127\n",
      "430559\n",
      "433368\n",
      "414192\n",
      "428081\n",
      "419836\n"
     ]
    }
   ],
   "source": [
    "# 监测输出窗口\n",
    "for line in detail:\n",
    "    print(len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube.to_csv(\"youtube_new.csv\",index = False, encoding = 'utf-8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
